{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b107c9-efd3-4c18-81d0-bdacc72a67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Matplotlib DPI Settings for High-Quality Images\n",
    "# -------------------------------------------------------------------\n",
    "matplotlib.rcParams['figure.dpi'] = 300\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Paths\n",
    "# -------------------------------------------------------------------\n",
    "dataset_path = \"/content/dataset/Indoor Object Detection Dataset\"  # Update if needed\n",
    "annotation_folder = os.path.join(dataset_path, \"annotation\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Parse XML Annotations\n",
    "# -------------------------------------------------------------------\n",
    "def parse_annotations(xml_files):\n",
    "    \"\"\"\n",
    "    Parses multiple XML annotation files into a single dictionary:\n",
    "        annotations[img_name] = {\n",
    "            \"boxes\": [[xmin, ymin, xmax, ymax], ...],\n",
    "            \"labels\": [label1, label2, ...]\n",
    "        }\n",
    "    Also returns a Counter for class distributions (bounding boxes).\n",
    "    \"\"\"\n",
    "    annotations = {}\n",
    "    class_counts = collections.Counter()\n",
    "\n",
    "    for xml_file in xml_files:\n",
    "        full_path = os.path.join(annotation_folder, xml_file)\n",
    "        if not os.path.isfile(full_path):\n",
    "            continue\n",
    "\n",
    "        tree = ET.parse(full_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for image_el in root.findall(\".//image\"):\n",
    "            img_name = os.path.basename(image_el.get(\"file\"))\n",
    "            boxes = []\n",
    "            labels = []\n",
    "\n",
    "            for box_el in image_el.findall(\"box\"):\n",
    "                xmin = int(box_el.get(\"left\"))\n",
    "                ymin = int(box_el.get(\"top\"))\n",
    "                w = int(box_el.get(\"width\"))\n",
    "                h = int(box_el.get(\"height\"))\n",
    "                xmax = xmin + w\n",
    "                ymax = ymin + h\n",
    "\n",
    "                label_el = box_el.find(\"label\")\n",
    "                label = label_el.text.strip() if label_el is not None else \"unknown\"\n",
    "\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(label)\n",
    "                class_counts[label] += 1\n",
    "\n",
    "            annotations[img_name] = {\n",
    "                \"boxes\": boxes,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "\n",
    "    return annotations, class_counts\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) Save Annotation & Update Dictionary\n",
    "# -------------------------------------------------------------------\n",
    "def save_annotation_for_augmented_image(\n",
    "    img_filename, boxes, labels, annotation_folder, annotations_dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a new XML file in 'annotation_folder' for the augmented image,\n",
    "    and also updates 'annotations_dict' so the new image is recognized\n",
    "    in the same run (avoiding \"No annotations found...\" messages).\n",
    "    \"\"\"\n",
    "    # Build the XML structure\n",
    "    root = ET.Element(\"annotations\")\n",
    "    images_el = ET.SubElement(root, \"images\")\n",
    "    image_el = ET.SubElement(images_el, \"image\", file=img_filename)\n",
    "\n",
    "    for (xmin, ymin, xmax, ymax), lab in zip(boxes, labels):\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        box_el = ET.SubElement(\n",
    "            image_el,\n",
    "            \"box\",\n",
    "            left=str(xmin),\n",
    "            top=str(ymin),\n",
    "            width=str(w),\n",
    "            height=str(h)\n",
    "        )\n",
    "        label_el = ET.SubElement(box_el, \"label\")\n",
    "        label_el.text = lab\n",
    "\n",
    "    # Write out the new XML\n",
    "    xml_name = os.path.splitext(img_filename)[0] + \".xml\"\n",
    "    xml_path = os.path.join(annotation_folder, xml_name)\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(xml_path)\n",
    "    print(f\"Saved annotation for augmented image: {xml_path}\")\n",
    "\n",
    "    # Update the annotations dictionary immediately\n",
    "    annotations_dict[img_filename] = {\n",
    "        \"boxes\": [[xmin, ymin, xmax, ymax] for (xmin, ymin, xmax, ymax) in boxes],\n",
    "        \"labels\": labels[:],\n",
    "    }\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) Data Augmentation Functions\n",
    "# -------------------------------------------------------------------\n",
    "def rotate_image(image, boxes, angle=15):\n",
    "    \"\"\"Rotates an image and adjusts bounding boxes.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "    # Rotate image\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "\n",
    "    # Rotate bounding boxes\n",
    "    rotated_boxes = []\n",
    "    for xmin, ymin, xmax, ymax in boxes:\n",
    "        points = np.array([\n",
    "            [xmin, ymin],\n",
    "            [xmax, ymin],\n",
    "            [xmax, ymax],\n",
    "            [xmin, ymax]\n",
    "        ], dtype=np.float32)\n",
    "        rotated_points = np.dot(rotation_matrix[:, :2], points.T).T + rotation_matrix[:, 2]\n",
    "        x_min_new, y_min_new = rotated_points.min(axis=0)\n",
    "        x_max_new, y_max_new = rotated_points.max(axis=0)\n",
    "        rotated_boxes.append([\n",
    "            int(x_min_new),\n",
    "            int(y_min_new),\n",
    "            int(x_max_new),\n",
    "            int(y_max_new)\n",
    "        ])\n",
    "\n",
    "    return rotated_image, rotated_boxes\n",
    "\n",
    "def flip_image(image, boxes, w):\n",
    "    \"\"\"Horizontally flips an image and adjusts bounding boxes.\"\"\"\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    flipped_boxes = []\n",
    "    for xmin, ymin, xmax, ymax in boxes:\n",
    "        new_xmin = w - xmax\n",
    "        new_xmax = w - xmin\n",
    "        flipped_boxes.append([new_xmin, ymin, new_xmax, ymax])\n",
    "    return flipped_image, flipped_boxes\n",
    "\n",
    "def adjust_brightness(image, factor=1.3):\n",
    "    \"\"\"Adjusts image brightness.\"\"\"\n",
    "    return np.clip(image.astype(np.float32) * factor, 0, 255).astype(np.uint8)\n",
    "\n",
    "def apply_gaussian_blur(image):\n",
    "    \"\"\"Applies Gaussian blur to an image.\"\"\"\n",
    "    return cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6) Apply Augmentations & Save\n",
    "# -------------------------------------------------------------------\n",
    "def augment_and_save_images(image_path, annotations_dict):\n",
    "    \"\"\"\n",
    "    Applies augmentations to one image, saves the augmented images,\n",
    "    and also saves a new annotation XML for each augmented image.\n",
    "    Returns a dict mapping {aug_type -> (aug_image_path, aug_boxes, labels)}.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error loading {image_path}\")\n",
    "        return {}\n",
    "\n",
    "    img_name = os.path.basename(image_path)\n",
    "    ann = annotations_dict.get(img_name, {\"boxes\": [], \"labels\": []})\n",
    "    boxes, labels = ann[\"boxes\"], ann[\"labels\"]\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        print(f\"No bounding boxes for {img_name}, skipping augmentation.\")\n",
    "        return {}\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Perform each augmentation\n",
    "    angle_choice = random.choice([-15, 15])\n",
    "    rotated_img, rotated_boxes = rotate_image(img.copy(), boxes, angle_choice)\n",
    "    flipped_img, flipped_boxes = flip_image(img.copy(), boxes, w)\n",
    "    bright_img = adjust_brightness(img.copy())\n",
    "    blurred_img = apply_gaussian_blur(img.copy())\n",
    "\n",
    "    augmentations = {\n",
    "        \"rotated\":  (rotated_img,  rotated_boxes),\n",
    "        \"flipped\":  (flipped_img,  flipped_boxes),\n",
    "        \"bright\":   (bright_img,   boxes),  # same boxes\n",
    "        \"blurred\":  (blurred_img,  boxes)   # same boxes\n",
    "    }\n",
    "\n",
    "    aug_results = {}\n",
    "    dir_name = os.path.dirname(image_path)\n",
    "\n",
    "    for aug_type, (aug_img, aug_boxes) in augmentations.items():\n",
    "        # Construct new image name\n",
    "        base, ext = os.path.splitext(img_name)\n",
    "        aug_img_name = f\"{base}_{aug_type}{ext}\"\n",
    "        aug_img_path = os.path.join(dir_name, aug_img_name)\n",
    "\n",
    "        # Save the augmented image\n",
    "        cv2.imwrite(aug_img_path, aug_img)\n",
    "\n",
    "        # Save new XML annotation (and update dictionary!)\n",
    "        save_annotation_for_augmented_image(\n",
    "            img_filename=aug_img_name,\n",
    "            boxes=aug_boxes,\n",
    "            labels=labels,\n",
    "            annotation_folder=annotation_folder,\n",
    "            annotations_dict=annotations_dict\n",
    "        )\n",
    "\n",
    "        # Store info for potential visualization\n",
    "        aug_results[aug_type] = (aug_img_path, aug_boxes, labels)\n",
    "\n",
    "    return aug_results\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7) Visualization (Optional)\n",
    "# -------------------------------------------------------------------\n",
    "def draw_bounding_boxes(image, boxes, labels):\n",
    "    \"\"\"Draw bounding boxes and labels on an image.\"\"\"\n",
    "    for (xmin, ymin, xmax, ymax), lab in zip(boxes, labels):\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "        cv2.putText(image, lab, (xmin, ymin - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "                    (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "def visualize_augmented_samples(original_img_path, aug_img_path, aug_boxes, aug_labels):\n",
    "    \"\"\"\n",
    "    Display the original image (with boxes) vs. augmented image (with boxes) side by side.\n",
    "    \"\"\"\n",
    "    orig_img = cv2.imread(original_img_path)\n",
    "    aug_img = cv2.imread(aug_img_path)\n",
    "    if orig_img is None or aug_img is None:\n",
    "        return\n",
    "\n",
    "    # Original bounding boxes\n",
    "    orig_name = os.path.basename(original_img_path)\n",
    "    global annotations\n",
    "    ann = annotations.get(orig_name, {\"boxes\": [], \"labels\": []})\n",
    "    orig_boxes, orig_labels = ann[\"boxes\"], ann[\"labels\"]\n",
    "\n",
    "    orig_drawn = draw_bounding_boxes(orig_img.copy(), orig_boxes, orig_labels)\n",
    "    aug_drawn = draw_bounding_boxes(aug_img.copy(), aug_boxes, aug_labels)\n",
    "\n",
    "    plt.figure(figsize=(8, 4), dpi=300)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(orig_drawn, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(aug_drawn, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Augmented\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 8) Count Images & Class Distribution\n",
    "# -------------------------------------------------------------------\n",
    "def count_images_and_class_distribution(dataset_path, annotation_folder):\n",
    "    \"\"\"\n",
    "    1) Count how many images (all .jpg/.png) in 'sequence_*' folders.\n",
    "    2) Parse all XML files to get bounding box class distribution.\n",
    "    \"\"\"\n",
    "    # Count images\n",
    "    total_images = 0\n",
    "    for seq in os.listdir(dataset_path):\n",
    "        seq_path = os.path.join(dataset_path, seq)\n",
    "        if os.path.isdir(seq_path) and seq.startswith(\"sequence_\"):\n",
    "            # Count files that end in .jpg/.png/.jpeg\n",
    "            image_files = [f for f in os.listdir(seq_path)\n",
    "                           if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "            total_images += len(image_files)\n",
    "\n",
    "    # Finally, parse ALL XML files (original + new)\n",
    "    all_xml_files = [f for f in os.listdir(annotation_folder) if f.endswith(\".xml\")]\n",
    "    _, class_counts = parse_annotations(all_xml_files)\n",
    "\n",
    "    print(\"\\n--- Dataset Summary After Augmentation ---\")\n",
    "    print(f\"Total images in dataset: {total_images}\")\n",
    "    print(\"Class distribution (bounding boxes):\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"  {cls}: {count}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 9) Main: Process All Sequences\n",
    "# -------------------------------------------------------------------\n",
    "def process_all_sequences():\n",
    "    \"\"\"\n",
    "    1) Parse the original XML files (annotation_s1.xml to annotation_s6.xml)\n",
    "       to build our 'annotations' dictionary.\n",
    "    2) For each 'sequence_*' folder, pick 3 images, augment them, and\n",
    "       visualize up to 3 augmented results.\n",
    "    3) At the end, parse all XML files again to see the final distribution.\n",
    "    \"\"\"\n",
    "    # (Alternative Start) If you want to parse ALL existing XMLs from the start:\n",
    "    #   all_xml_files = [f for f in os.listdir(annotation_folder) if f.endswith(\".xml\")]\n",
    "    #   global annotations\n",
    "    #   annotations, _ = parse_annotations(all_xml_files)\n",
    "\n",
    "    # Otherwise, parse only the original known XMLs:\n",
    "    original_xmls = [f\"annotation_s{i}.xml\" for i in range(1, 7)]\n",
    "    global annotations\n",
    "    annotations, _ = parse_annotations(original_xmls)\n",
    "\n",
    "    # 2) For each sequence_* folder, pick 3 images, augment them, and visualize\n",
    "    for seq in sorted(os.listdir(dataset_path)):\n",
    "        seq_path = os.path.join(dataset_path, seq)\n",
    "        if not os.path.isdir(seq_path) or not seq.startswith(\"sequence_\"):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing folder: {seq}...\")\n",
    "        image_files = [f for f in os.listdir(seq_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        if not image_files:\n",
    "            print(f\"No images found in {seq}\")\n",
    "            continue\n",
    "\n",
    "        # Randomly pick 3 images from the sequence\n",
    "        sample_count = min(3, len(image_files))\n",
    "        chosen_files = random.sample(image_files, sample_count)\n",
    "\n",
    "        # We will store info about augmented images for visualization\n",
    "        aug_visual_list = []\n",
    "\n",
    "        for img_file in chosen_files:\n",
    "            img_path = os.path.join(seq_path, img_file)\n",
    "            # Perform augmentations (rotated, flipped, bright, blurred)\n",
    "            aug_results = augment_and_save_images(img_path, annotations)\n",
    "\n",
    "            # Pick exactly one augmented type to visualize (e.g., \"rotated\")\n",
    "            if aug_results:\n",
    "                chosen_aug_type = random.choice(list(aug_results.keys()))\n",
    "                aug_img_path, aug_boxes, aug_labels = aug_results[chosen_aug_type]\n",
    "                aug_visual_list.append((img_path, aug_img_path, aug_boxes, aug_labels))\n",
    "\n",
    "        # Now visualize up to 3 augmented results side-by-side\n",
    "        max_to_show = min(3, len(aug_visual_list))\n",
    "        for i in range(max_to_show):\n",
    "            orig_path, a_path, a_boxes, a_labels = aug_visual_list[i]\n",
    "            visualize_augmented_samples(orig_path, a_path, a_boxes, a_labels)\n",
    "\n",
    "    # 3) After all augmentations, parse ALL XMLs for final distribution\n",
    "    count_images_and_class_distribution(dataset_path, annotation_folder)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 10) Run\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_sequences()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
